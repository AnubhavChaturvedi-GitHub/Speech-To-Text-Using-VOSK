# ğŸ—£ï¸ Speech-to-Text Using VOSK

### ğŸš€ Transform Audio into Text with Precision and Speed

This project demonstrates how to build a real-time **Speech-to-Text** system using the **VOSK** library. Whether you're creating transcription tools, virtual assistants, or voice-controlled systems, this implementation ensures high accuracy and efficiency.

---
![Demo GIF](https://github.com/user-attachments/assets/255c2c3d-99dc-4752-8469-6ef64f42e267)

## ğŸ“‹ Features

- **Real-Time Transcription**: Converts live audio into text instantly.
- **Lightweight & Offline**: Works offline without requiring heavy resources.
- **High Accuracy**: Supports multiple languages with pre-trained models.
- **Customizable**: Easily adapt the code for different use cases.

---

## ğŸ› ï¸ Setup

### Prerequisites

1. **Python (3.6 or higher)**: Ensure Python is installed on your machine.
2. **Create a Virtual Environment (optional but recommended)**:
   ```bash
   python -m venv venv
   ```
   Activate the virtual environment:
   - On **Windows**:
     ```bash
     .\venv\Scripts\activate
     ```
   - On **macOS/Linux**:
     ```bash
     source venv/bin/activate
     ```
3. **Install Dependencies**:
   - Install the required Python libraries:
     ```bash
     pip install -r requirements.txt
     ```

4. **Download a VOSK Model**:
   - Download a pre-trained VOSK model from the official VOSK model page: [VOSK Models](https://alphacephei.com/vosk/models).
   - **Models available**:
     | Model Name                       | Languages     | Link                                                                                       |
     | -------------------------------- | ------------- | ------------------------------------------------------------------------------------------ |
     | `vosk-model-small-en-us-0.15`    | English (US)  | [Download](https://alphacephei.com/vosk/models/vosk-model-small-en-us-0.15)                |
     | `vosk-model-small-hi-in-0.22`    | Hindi (IN)    | [Download](https://alphacephei.com/vosk/models/vosk-model-small-hi-in-0.22)                |
     | `vosk-model-en-us`               | English (US)  | [Download](https://alphacephei.com/vosk/models/vosk-model-en-us)                           |
     | `vosk-model-small-fr-fr-0.15`    | French        | [Download](https://alphacephei.com/vosk/models/vosk-model-small-fr-fr-0.15)                |
     | `vosk-model-small-de-de-0.15`    | German        | [Download](https://alphacephei.com/vosk/models/vosk-model-small-de-de-0.15)                |

   - Extract the downloaded model into a directory (e.g., `vosk-model-small-en-us-0.15`).

---

## ğŸ“‚ Project Structure

```
â”œâ”€â”€ SpeechToTextUsingVosk.py        # Main Python file to run the application
â”œâ”€â”€ models                         # Directory containing the downloaded models
    â””â”€â”€ vosk-model-small-en-us-0.15
        â”œâ”€â”€ README
        â”œâ”€â”€ am
        â”‚   â””â”€â”€ final.mdl
        â”œâ”€â”€ conf
        â”‚   â”œâ”€â”€ mfcc.conf
        â”‚   â””â”€â”€ model.conf
        â”œâ”€â”€ graph
        â”‚   â”œâ”€â”€ Gr.fst
        â”‚   â”œâ”€â”€ HCLr.fst
        â”‚   â”œâ”€â”€ disambig_tid.int
        â”‚   â””â”€â”€ phones
        â”‚       â””â”€â”€ word_boundary.int
        â””â”€â”€ ivector
            â”œâ”€â”€ final.dubm
            â”œâ”€â”€ final.ie
            â”œâ”€â”€ final.mat
            â”œâ”€â”€ global_cmvn.stats
            â”œâ”€â”€ online_cmvn.conf
            â””â”€â”€ splice.conf
â”œâ”€â”€ readme.md                      # Project documentation
â””â”€â”€ requirements.txt               # Python dependencies
```

---

## ğŸš€ Usage

1. **Clone the Repository**:
   ```bash
   git clone https://github.com/YourUsername/speech-to-text-vosk.git
   cd speech-to-text-vosk
   ```

2. **Set Model Path**:
   Replace the `MODEL_PATH` in `SpeechToTextUsingVosk.py` with the path to your downloaded VOSK model directory.

3. **Run the Application**:
   ```bash
   python SpeechToTextUsingVosk.py
   ```

4. **Start Speaking**:
   Speak into your microphone and watch as your speech is converted into text in real-time!

---

## ğŸ§© How It Works

1. **Audio Capture**: The `sounddevice` library is used to capture live audio input from the microphone.
2. **Processing with VOSK**: The captured audio is processed in real-time by VOSK's speech recognizer.
3. **Real-Time Output**: The system outputs both partial and final transcriptions as you speak.

---

## ğŸ“ˆ Performance Tips

- **For Faster Transcription**: Use smaller models such as `vosk-model-small-en-us-0.15` for real-time transcription on low-resource systems.
- **For Higher Accuracy**: Download larger models for better accuracy, such as `vosk-model-en-us`.
- **Ensure a Quiet Environment**: Background noise can affect transcription accuracy. Ensure you're in a quiet space for optimal results.

---

## ğŸ“‹ Example Output

### Input:
_"Hello, welcome to the VOSK speech-to-text demo!"_

### Output:
```json
{
  "text": "hello welcome to the vosk speech to text demo"
}
```

---

## ğŸ“š Resources

- [VOSK Documentation](https://alphacephei.com/vosk/)
- [Pre-Trained Models](https://alphacephei.com/vosk/models)
- [SoundDevice Library](https://python-sounddevice.readthedocs.io/)

---

## ğŸ¤ Contribution

Contributions are welcome! Feel free to fork the repository, submit issues, or create pull requests.  

---

## ğŸ“œ License

This project is licensed under the **MIT License**. See the [LICENSE](LICENSE) file for details.

---

## ğŸ§‘â€ğŸ’» About the Creator

Developed with ğŸ’¡ by **Anubhav Chaturvedi** (@NetHyTech).  
Check out more open-source projects on [GitHub](https://github.com/AnubhavChaturvedi-GitHub).  

